arguments: app.py
--------------------
git hash: 00a78f607324ae681643352c082052004e7774b5
--------------------
diff --git a/src/__init__.py b/src/__init__.py
index efa6252..c4be86d 100644
--- a/src/__init__.py
+++ b/src/__init__.py
@@ -1,2 +1,2 @@
 # flake8: noqa
-
+__all__ = ['classifier', 'facenet']
diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py
index d2a3eea..e0951ba 100644
--- a/src/align/align_dataset_mtcnn.py
+++ b/src/align/align_dataset_mtcnn.py
@@ -31,7 +31,7 @@ import os
 import argparse
 import tensorflow as tf
 import numpy as np
-import facenet
+import facenet.src.facenet as facenet
 import align.detect_face
 import random
 from time import sleep
@@ -123,6 +123,99 @@ def main(args):
     print('Total number of images: %d' % nrof_images_total)
     print('Number of successfully aligned images: %d' % nrof_successfully_aligned)
             
+def align_dataset(output_dir,
+            input_dir,
+            gpu_memory_fraction,
+            random_order,
+            margin,
+            image_size):
+    sleep(random.random())
+    output_dir = os.path.expanduser(output_dir)
+    if not os.path.exists(output_dir):
+        os.makedirs(output_dir)
+    # Store some git revision info in a text file in the log directory
+    src_path,_ = os.path.split(os.path.realpath(__file__))
+    facenet.store_revision_info(src_path, output_dir, ' '.join(sys.argv))
+    dataset = facenet.get_dataset(input_dir)
+    
+    print('Creating networks and loading parameters')
+    
+    with tf.Graph().as_default():
+        # gpu_options = tf.GPUOptions(gpu_memory_fraction)
+        # sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))
+        sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))
+        with sess.as_default():
+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)
+    
+    minsize = 20 # minimum size of face
+    threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold
+    factor = 0.709 # scale factor
+
+    # Add a random key to the filename to allow alignment using multiple processes
+    random_key = np.random.randint(0, high=99999)
+    bounding_boxes_filename = os.path.join(output_dir, 'bounding_boxes_%05d.txt' % random_key)
+    
+    with open(bounding_boxes_filename, "w") as text_file:
+        nrof_images_total = 0
+        nrof_successfully_aligned = 0
+        if random_order:
+            random.shuffle(dataset)
+        for cls in dataset:
+            output_class_dir = os.path.join(output_dir, cls.name)
+            if not os.path.exists(output_class_dir):
+                os.makedirs(output_class_dir)
+                if random_order:
+                    random.shuffle(cls.image_paths)
+            for image_path in cls.image_paths:
+                nrof_images_total += 1
+                filename = os.path.splitext(os.path.split(image_path)[1])[0]
+                output_filename = os.path.join(output_class_dir, filename+'.png')
+                print(image_path)
+                if not os.path.exists(output_filename):
+                    try:
+                        img = misc.imread(image_path)
+                    except (IOError, ValueError, IndexError) as e:
+                        errorMessage = '{}: {}'.format(image_path, e)
+                        print(errorMessage)
+                    else:
+                        if img.ndim<2:
+                            print('Unable to align "%s"' % image_path)
+                            text_file.write('%s\n' % (output_filename))
+                            continue
+                        if img.ndim == 2:
+                            img = facenet.to_rgb(img)
+                        img = img[:,:,0:3]
+    
+                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)
+                        nrof_faces = bounding_boxes.shape[0]
+                        if nrof_faces>0:
+                            det = bounding_boxes[:,0:4]
+                            img_size = np.asarray(img.shape)[0:2]
+                            if nrof_faces>1:
+                                bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])
+                                img_center = img_size / 2
+                                offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])
+                                offset_dist_squared = np.sum(np.power(offsets,2.0),0)
+                                index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering
+                                det = det[index,:]
+                            det = np.squeeze(det)
+                            bb = np.zeros(4, dtype=np.int32)
+                            bb[0] = np.maximum(det[0]-margin/2, 0)
+                            bb[1] = np.maximum(det[1]-margin/2, 0)
+                            bb[2] = np.minimum(det[2]+margin/2, img_size[1])
+                            bb[3] = np.minimum(det[3]+margin/2, img_size[0])
+                            cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]
+                            scaled = misc.imresize(cropped, (image_size, image_size), interp='bilinear')
+                            nrof_successfully_aligned += 1
+                            misc.imsave(output_filename, scaled)
+                            text_file.write('%s %d %d %d %d\n' % (output_filename, bb[0], bb[1], bb[2], bb[3]))
+                        else:
+                            print('Unable to align "%s"' % image_path)
+                            text_file.write('%s\n' % (output_filename))
+                            
+    print('Total number of images: %d' % nrof_images_total)
+    print('Number of successfully aligned images: %d' % nrof_successfully_aligned)
+    
 
 def parse_arguments(argv):
     parser = argparse.ArgumentParser()
diff --git a/src/classifier.py b/src/classifier.py
index 749db4d..072b54f 100644
--- a/src/classifier.py
+++ b/src/classifier.py
@@ -29,7 +29,7 @@ from __future__ import print_function
 import tensorflow as tf
 import numpy as np
 import argparse
-import facenet
+import facenet.src.facenet as facenet
 import os
 import sys
 import math
@@ -104,6 +104,7 @@ def main(args):
                 print('Saved classifier model to file "%s"' % classifier_filename_exp)
                 
             elif (args.mode=='CLASSIFY'):
+                res = []
                 # Classify images
                 print('Testing classifier')
                 with open(classifier_filename_exp, 'rb') as infile:
@@ -117,11 +118,169 @@ def main(args):
                 
                 for i in range(len(best_class_indices)):
                     print('%4d  %s: %.3f' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))
-                    
+                    res.append((i, class_names[best_class_indices[i]], best_class_probabilities))
+                # print(best_class_indices)
+                # print(labels)    
                 accuracy = np.mean(np.equal(best_class_indices, labels))
                 print('Accuracy: %.3f' % accuracy)
+
+                return res                
+
+def train(use_split_dataset,
+            mode,
+            data_dir, 
+            min_nrof_images_per_class, 
+            nrof_train_images_per_class,
+            model,
+            classifier_filename,
+            batch_size,
+            image_size):
+    
+    seed = 666
+
+    with tf.Graph().as_default():    
+        with tf.Session() as sess:
+            np.random.seed(seed=seed)
+            
+            if use_split_dataset:
+                dataset_tmp = facenet.get_dataset(data_dir)
+                train_set, test_set = split_dataset(dataset_tmp, min_nrof_images_per_class, nrof_train_images_per_class)
+                if (args.mode=='TRAIN'):
+                    dataset = train_set
+                elif (args.mode=='CLASSIFY'):
+                    dataset = test_set
+            else:
+                dataset = facenet.get_dataset(data_dir)
+
+            # Check that there are at least one training image per class
+            for cls in dataset:
+                assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')            
+ 
+            paths, labels = facenet.get_image_paths_and_labels(dataset)
+            
+            # print('Number of classes: %d' % len(dataset))
+            # print('Number of images: %d' % len(paths))
+            
+            # Load the model
+            # print('Loading feature extraction model')
+            facenet.load_model(model)
+            
+            # Get input and output tensors
+            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
+            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")
+            embedding_size = embeddings.get_shape()[1]
+            
+            # Run forward pass to calculate embeddings
+            print('Calculating features for images')
+            nrof_images = len(paths)
+            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / batch_size))
+            emb_array = np.zeros((nrof_images, embedding_size))
+            for i in range(nrof_batches_per_epoch):
+                start_index = i*batch_size
+                end_index = min((i+1)*batch_size, nrof_images)
+                paths_batch = paths[start_index:end_index]
+                images = facenet.load_data(paths_batch, False, False, image_size)
+                feed_dict = { images_placeholder:images, phase_train_placeholder:False }
+                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)
+            
+            classifier_filename_exp = os.path.expanduser(classifier_filename)
+    
+            print('Training classifier')
+            model = SVC(kernel='linear', probability=True)
+            model.fit(emb_array, labels)
+            
+                # Create a list of class names
+            class_names = [ cls.name.replace('_', ' ') for cls in dataset]
+
+                # Saving classifier model
+            with open(classifier_filename_exp, 'wb') as outfile:
+                pickle.dump((model, class_names), outfile)
+            print('Saved classifier model to file "%s"' % classifier_filename_exp)
+                    
+
+def classify(use_split_dataset,
+            mode,
+            data_dir, 
+            min_nrof_images_per_class, 
+            nrof_train_images_per_class,
+            model,
+            classifier_filename,
+            batch_size,
+            image_size):
                 
+    seed = 666
+    with tf.Graph().as_default():    
+        with tf.Session() as sess:
+            np.random.seed(seed=seed)
             
+            if use_split_dataset:
+                dataset_tmp = facenet.get_dataset(data_dir)
+                train_set, test_set = split_dataset(dataset_tmp, min_nrof_images_per_class, nrof_train_images_per_class)
+                if (args.mode=='TRAIN'):
+                    dataset = train_set
+                elif (args.mode=='CLASSIFY'):
+                    dataset = test_set
+            else:
+                dataset = facenet.get_dataset(data_dir)
+
+            # Check that there are at least one training image per class
+            for cls in dataset:
+                assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')            
+ 
+            paths, labels = facenet.get_image_paths_and_labels(dataset)
+            
+            # print('Number of classes: %d' % len(dataset))
+            # print('Number of images: %d' % len(paths))
+            
+            # Load the model
+            # print('Loading feature extraction model')
+            facenet.load_model(model)
+            
+            # Get input and output tensors
+            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
+            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")
+            embedding_size = embeddings.get_shape()[1]
+            
+            # Run forward pass to calculate embeddings
+            print('Calculating features for images')
+            nrof_images = len(paths)
+            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / batch_size))
+            emb_array = np.zeros((nrof_images, embedding_size))
+            for i in range(nrof_batches_per_epoch):
+                start_index = i*batch_size
+                end_index = min((i+1)*batch_size, nrof_images)
+                paths_batch = paths[start_index:end_index]
+                images = facenet.load_data(paths_batch, False, False, image_size)
+                feed_dict = { images_placeholder:images, phase_train_placeholder:False }
+                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)
+            
+            classifier_filename_exp = os.path.expanduser(classifier_filename)
+          
+            res = []
+
+            # print('Testing classifier')
+            with open(classifier_filename_exp, 'rb') as infile:
+                (model, class_names) = pickle.load(infile)
+
+            # print('Loaded classifier model from file "%s"' % classifier_filename_exp)
+
+            predictions = model.predict_proba(emb_array)
+            best_class_indices = np.argmax(predictions, axis=1)
+            best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]
+                
+            for i in range(len(best_class_indices)):
+                print('%4d  %s: %.3f' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))
+                res.append((i, class_names[best_class_indices[i]], best_class_probabilities[i]))
+                    
+            accuracy = np.mean(np.equal(best_class_indices, labels))
+            print('Accuracy: %.3f' % accuracy)
+
+            return res                
+                
+
+
 def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):
     train_set = []
     test_set = []